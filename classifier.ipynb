{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories\n",
    "\n",
    "GAME_CATEGORIES = ['DILETTAN', 'ASTROPE', 'GLENDALE', 'GRANGER', 'CAVCADE']\n",
    "REAL_CATEGORIES = ['2009 Toyota Prius', '2015 BMW M3', '1992 Mercedes-Benz 500E',\n",
    "                   '2016 Dodge Ram Rebel', '2016 Audi Q7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline parameters\n",
    "\n",
    "IMG_SIZE = 50\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "IMAGES_PER_CATEGORY = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_DATA = False\n",
    "\n",
    "class GTACars():\n",
    "    _img_size = IMG_SIZE\n",
    "    _categories = GAME_CATEGORIES\n",
    "    _training_data = []\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        self.labels = {}\n",
    "        for i, label in enumerate(self._categories):\n",
    "            self.labels[label] = i\n",
    "        for label in self.labels:\n",
    "            label_count = 0\n",
    "            for f in os.listdir(f'processed_images/{label}'):\n",
    "                try:\n",
    "                    path = os.path.join(f'processed_images/{label}', f)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img = cv2.resize(img, (self._img_size, self._img_size))\n",
    "                    self._training_data.append([np.array(img), self.labels[label]])\n",
    "                    label_count += 1\n",
    "                    if label_count == IMAGES_PER_CATEGORY:\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "        np.random.shuffle(self._training_data)\n",
    "        np.save('training_data.npy', self._training_data)\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    gta_cars = GTACars()\n",
    "    gta_cars.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading training data\n",
    "\n",
    "training_data = np.load('training_data.npy', allow_pickle=True)\n",
    "random.shuffle(training_data)\n",
    "print(f'Loaded {len(training_data)} training images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying example of training data\n",
    "\n",
    "print(f'Training Data Example Class Number: {training_data[0][1]}')\n",
    "print(f'Training Data Example Category:     {REAL_CATEGORIES[training_data[0][1]]}')\n",
    "\n",
    "plt.imshow(training_data[0][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        \n",
    "        x = torch.randn(IMG_SIZE, IMG_SIZE).view(-1, 1, IMG_SIZE, IMG_SIZE)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "\n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and loss function\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting image and label tensors\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1, IMG_SIZE, IMG_SIZE)\n",
    "X = X / 255.0\n",
    "y = torch.Tensor([i[1] for i in training_data]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test\n",
    "\n",
    "TEST_RATIO = 0.1\n",
    "test_size = int(len(X) * TEST_RATIO)\n",
    "\n",
    "train_X = X[:-test_size]\n",
    "train_y = y[:-test_size]\n",
    "\n",
    "test_X = X[-test_size:]\n",
    "test_y = y[-test_size:]\n",
    "\n",
    "print(f'Training Sample Count: {len(train_X)}')\n",
    "print(f'Test Sample Count:     {len(test_X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "n_iter = 0\n",
    "epoch_losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(train_X), BATCH_SIZE):\n",
    "        batch_X = train_X[i:i + BATCH_SIZE].view(-1, 1, IMG_SIZE, IMG_SIZE)\n",
    "        batch_y = train_y[i:i + BATCH_SIZE]\n",
    "        \n",
    "        net.zero_grad()\n",
    "        outputs = net(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        n_iter += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    epoch_losses.append(total_loss / (len(train_X) // BATCH_SIZE))\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1} | Average Loss: {total_loss / (len(train_X) // BATCH_SIZE)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy measurment\n",
    "\n",
    "predictions = []\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_X)):\n",
    "        real_class = test_y[i]\n",
    "        net_out = net(test_X[i].view(-1, 1, IMG_SIZE, IMG_SIZE))[0]\n",
    "        predicted_class = torch.argmax(net_out)\n",
    "        predictions.append(predicted_class)\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "print(f'Accuracy: {round(correct / total, 3)}\\n')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(test_y, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples of predictions with images displayed\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure()\n",
    "    plt.title(f'Predicted: {REAL_CATEGORIES[predictions[i]]}\\nReal: {REAL_CATEGORIES[test_y[i]]}')\n",
    "    image = cv2.cvtColor(test_X[i].view(IMG_SIZE, IMG_SIZE).numpy(), cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc",
   "language": "python",
   "name": "vc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
